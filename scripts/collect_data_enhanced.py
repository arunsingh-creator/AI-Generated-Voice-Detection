"""
Enhanced Data Collection Script with Multiple TTS Engines
Generates diverse AI voice samples for improved model training
"""
import os
import sys
from pathlib import Path
from gtts import gTTS
import logging

# Add parent directory to path
sys.path.append(str(Path(__file__).parent.parent))

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(message)s')
logger = logging.getLogger(__name__)


# Sample texts for each language
SAMPLE_TEXTS = {
    "en": [
        "Hello, this is a test of the AI voice detection system.",
        "The weather today is quite pleasant with clear skies.",
        "Technology has transformed the way we communicate.",
        "Machine learning is revolutionizing many industries.",
        "This recording will help train an artificial intelligence model.",
        "Science and innovation drive progress in our society.",
        "Education is the foundation of a successful future.",
    ],
    "ta": [
        "à®µà®£à®•à¯à®•à®®à¯, à®‡à®¤à¯ à®šà¯†à®¯à®±à¯à®•à¯ˆ à®¨à¯à®£à¯à®£à®±à®¿à®µà¯ à®•à¯à®°à®²à¯ à®•à®£à¯à®Ÿà®±à®¿à®¤à®²à¯ à®…à®®à¯ˆà®ªà¯à®ªà®¿à®©à¯ à®šà¯‹à®¤à®©à¯ˆ.",
        "à®‡à®©à¯à®±à¯ à®µà®¾à®©à®¿à®²à¯ˆ à®®à®¿à®•à®µà¯à®®à¯ à®‡à®©à®¿à®®à¯ˆà®¯à®¾à®• à®‰à®³à¯à®³à®¤à¯.",
        "à®¤à¯Šà®´à®¿à®²à¯à®¨à¯à®Ÿà¯à®ªà®®à¯ à®¨à®®à¯ à®¤à¯Šà®Ÿà®°à¯à®ªà¯ à®®à¯à®±à¯ˆà®¯à¯ˆ à®®à®¾à®±à¯à®±à®¿à®¯à¯à®³à¯à®³à®¤à¯.",
        "à®‡à®¯à®¨à¯à®¤à®¿à®° à®•à®±à¯à®±à®²à¯ à®ªà®² à®¤à¯Šà®´à®¿à®²à¯à®•à®³à¯ˆ à®ªà¯à®°à®Ÿà¯à®šà®¿à®•à®°à®®à®¾à®• à®®à®¾à®±à¯à®±à¯à®•à®¿à®±à®¤à¯.",
    ],
    "hi": [
        "à¤¨à¤®à¤¸à¥à¤¤à¥‡, à¤¯à¤¹ à¤à¤†à¤ˆ à¤µà¥‰à¤¯à¤¸ à¤¡à¤¿à¤Ÿà¥‡à¤•à¥à¤¶à¤¨ à¤¸à¤¿à¤¸à¥à¤Ÿà¤® à¤•à¤¾ à¤ªà¤°à¥€à¤•à¥à¤·à¤£ à¤¹à¥ˆà¥¤",
        "à¤†à¤œ à¤•à¤¾ à¤®à¥Œà¤¸à¤® à¤¸à¤¾à¤« à¤†à¤¸à¤®à¤¾à¤¨ à¤•à¥‡ à¤¸à¤¾à¤¥ à¤•à¤¾à¤«à¥€ à¤¸à¥à¤¹à¤¾à¤µà¤¨à¤¾ à¤¹à¥ˆà¥¤",
        "à¤ªà¥à¤°à¥Œà¤¦à¥à¤¯à¥‹à¤—à¤¿à¤•à¥€ à¤¨à¥‡ à¤¹à¤®à¤¾à¤°à¥‡ à¤¸à¤‚à¤µà¤¾à¤¦ à¤•à¥‡ à¤¤à¤°à¥€à¤•à¥‡ à¤•à¥‹ à¤¬à¤¦à¤² à¤¦à¤¿à¤¯à¤¾ à¤¹à¥ˆà¥¤",
        "à¤®à¤¶à¥€à¤¨ à¤²à¤°à¥à¤¨à¤¿à¤‚à¤— à¤•à¤ˆ à¤‰à¤¦à¥à¤¯à¥‹à¤—à¥‹à¤‚ à¤®à¥‡à¤‚ à¤•à¥à¤°à¤¾à¤‚à¤¤à¤¿ à¤²à¤¾ à¤°à¤¹à¥€ à¤¹à¥ˆà¥¤",
    ],
    "ml": [
        "à´¹à´²àµ‹, à´‡à´¤àµ AI à´µàµ‹à´¯àµâ€Œà´¸àµ à´¡à´¿à´±àµà´±à´•àµà´·àµ» à´¸à´¿à´¸àµà´±àµà´±à´¤àµà´¤à´¿à´¨àµà´±àµ† à´ªà´°à´¿à´¶àµ‹à´§à´¨à´¯à´¾à´£àµ.",
        "à´‡à´¨àµà´¨à´¤àµà´¤àµ† à´•à´¾à´²à´¾à´µà´¸àµà´¥ à´µà´³à´°àµ† à´¸àµà´–à´•à´°à´®à´¾à´£àµ.",
        "à´¸à´¾à´™àµà´•àµ‡à´¤à´¿à´•à´µà´¿à´¦àµà´¯ à´¨à´®àµà´®àµà´Ÿàµ† à´†à´¶à´¯à´µà´¿à´¨à´¿à´®à´¯ à´°àµ€à´¤à´¿à´¯àµ† à´®à´¾à´±àµà´±à´¿à´®à´±à´¿à´šàµà´šà´¿à´°à´¿à´•àµà´•àµà´¨àµà´¨àµ.",
    ],
    "te": [
        "à°¹à°²à±‹, à°‡à°¦à°¿ AI à°µà°¾à°¯à°¿à°¸à± à°¡à°¿à°Ÿà±†à°•à±à°·à°¨à± à°¸à°¿à°¸à±à°Ÿà°®à± à°¯à±Šà°•à±à°• à°ªà°°à±€à°•à±à°·.",
        "à°ˆà°°à±‹à°œà± à°µà°¾à°¤à°¾à°µà°°à°£à°‚ à°šà°¾à°²à°¾ à°†à°¹à±à°²à°¾à°¦à°•à°°à°‚à°—à°¾ à°‰à°‚à°¦à°¿.",
        "à°¸à°¾à°‚à°•à±‡à°¤à°¿à°•à°¤ à°®à°¨ à°•à°®à±à°¯à±‚à°¨à°¿à°•à±‡à°·à°¨à± à°µà°¿à°§à°¾à°¨à°¾à°¨à±à°¨à°¿ à°®à°¾à°°à±à°šà°¿à°‚à°¦à°¿.",
    ],
}


def generate_gtts_samples(output_dir: Path, languages: dict):
    """Generate basic gTTS samples (existing method)"""
    logger.info("\nðŸ“¢ Generating AI samples using gTTS...")
    
    ai_dir = output_dir / "ai"
    ai_dir.mkdir(parents=True, exist_ok=True)
    
    count = 0
    for lang_code, texts in languages.items():
        for i, text in enumerate(texts, 1):
            try:
                output_file = ai_dir / f"ai_{lang_code}_{i}.mp3"
                tts = gTTS(text=text, lang=lang_code)
                tts.save(str(output_file))
                logger.info(f"  âœ“ Generated: {output_file.name}")
                count += 1
            except Exception as e:
                logger.error(f"  âœ— Failed to generate {lang_code}_{i}: {e}")
    
    return count


def generate_coqui_tts_samples(output_dir: Path, languages: dict):
    """Generate samples using Coqui TTS (local, high quality)"""
    logger.info("\nðŸ“¢ Generating AI samples using Coqui TTS...")
    
    try:
        from TTS.api import TTS
        
        ai_dir = output_dir / "ai_coqui"
        ai_dir.mkdir(parents=True, exist_ok=True)
        
        # Initialize TTS model
        logger.info("  Loading Coqui TTS model...")
        tts = TTS(model_name="tts_models/en/ljspeech/tacotron2-DDC")
        
        count = 0
        # For now, only English (Coqui has limited multilingual support)
        if "en" in languages:
            for i, text in enumerate(languages["en"], 1):
                try:
                    output_file = ai_dir / f"ai_coqui_en_{i}.wav"
                    tts.tts_to_file(text=text, file_path=str(output_file))
                    logger.info(f"  âœ“ Generated: {output_file.name}")
                    count += 1
                except Exception as e:
                    logger.error(f"  âœ— Failed: {e}")
        
        logger.info(f"\nâœ“ Generated {count} Coqui TTS samples")
        return count
        
    except ImportError:
        logger.warning("âš  Coqui TTS not installed. Install with: pip install TTS")
        logger.info("  Skipping Coqui TTS generation...")
        return 0
    except Exception as e:
        logger.warning(f"âš  Coqui TTS generation failed: {e}")
        return 0


def create_human_sample_instructions(output_dir: Path):
    """Create instructions for collecting real human voice samples"""
    human_dir = output_dir / "human"
    human_dir.mkdir(parents=True, exist_ok=True)
    
    instructions = """
====================================================================
INSTRUCTIONS FOR COLLECTING REAL HUMAN VOICE SAMPLES
====================================================================

CRITICAL: Real human voice samples are ESSENTIAL for achieving 80-85% accuracy!

OPTION 1: SELF-RECORDING (Fastest - 30 minutes)
------------------------------------------------
1. Equipment:
   - Smartphone voice recorder OR laptop microphone
   - Quiet room (minimal background noise)

2. Recording guidelines:
   - Record 5-10 samples per language
   - Each sample: 5-10 seconds
   - Speak naturally at normal pace
   - Vary tone/emotion slightly between samples
   - Save as MP3 format

3. Naming convention:
   - English: human_en_1.mp3, human_en_2.mp3, etc.
   - Tamil: human_ta_1.mp3, human_ta_2.mp3, etc.
   - Hindi: human_hi_1.mp3, human_hi_2.mp3, etc.
   - Malayalam: human_ml_1.mp3, human_ml_2.mp3, etc.
   - Telugu: human_te_1.mp3, human_te_2.mp3, etc.

4. Sample texts to read:
   Tamil: "à®µà®£à®•à¯à®•à®®à¯, à®Žà®©à¯ à®ªà¯†à®¯à®°à¯ [à®‰à®™à¯à®•à®³à¯ à®ªà¯†à®¯à®°à¯]. à®‡à®©à¯à®±à¯ à®¨à®¾à®©à¯ à®‡à®¨à¯à®¤ à®•à¯à®°à®²à¯ à®ªà®¤à®¿à®µà¯ˆ à®šà¯†à®¯à¯à®•à®¿à®±à¯‡à®©à¯."
   English: "Hello, my name is [your name]. I am recording this sample today."
   Hindi: "à¤¨à¤®à¤¸à¥à¤¤à¥‡, à¤®à¥‡à¤°à¤¾ à¤¨à¤¾à¤® [à¤†à¤ªà¤•à¤¾ à¤¨à¤¾à¤®] à¤¹à¥ˆà¥¤ à¤®à¥ˆà¤‚ à¤†à¤œ à¤¯à¤¹ à¤°à¤¿à¤•à¥‰à¤°à¥à¤¡à¤¿à¤‚à¤— à¤•à¤° à¤°à¤¹à¤¾ à¤¹à¥‚à¤‚à¥¤"
   (Add more varied sentences)

OPTION 2: PUBLIC DATASETS (Better Quality - 1-2 hours)
-------------------------------------------------------
1. Mozilla Common Voice (Recommended)
   - Website: https://commonvoice.mozilla.org/
   - Download validated datasets for your languages
   - Extract 10-20 samples per language
   - Already in MP3/OGG format
   
2. LibriVox (English only)
   - Website: https://librivox.org/
   - Public domain audiobooks
   - Download short clips, extract 5-10 second segments
   
3. VoxCeleb (Research dataset)
   - Website: https://www.robots.ox.ac.uk/~vgg/data/voxceleb/
   - Celebrity speech samples
   - Good speaker variety

OPTION 3: HYBRID (Recommended for Best Results)
------------------------------------------------
Combine sources for maximum diversity:
- 5 self-recorded samples per language
- 10 Mozilla Common Voice samples per language
- 5 LibriVox samples (English)

TARGET: 20+ human samples per language = 100+ total samples

====================================================================
QUICK START COMMAND
====================================================================

After collecting samples, verify:
    
    cd data/raw/human
    dir *.mp3  # Windows
    ls -l *.mp3  # Linux/Mac

Then retrain the model:
    
    python scripts/train_model.py

Expected accuracy improvement: 40-50% â†’ 75-85%

====================================================================
"""
    
    readme_file = human_dir / "README_HUMAN_SAMPLES.txt"
    with open(readme_file, 'w', encoding='utf-8') as f:
        f.write(instructions)
    
    logger.info(f"\nâœ“ Created instructions in {readme_file}")


def create_placeholder_samples(output_dir: Path):
    """Create placeholder 'human' samples for testing (AI-generated with variation)"""
    response = input("\nWould you like to create placeholder 'human' samples for testing?\n"
                    "(These are AI-generated with variation - NOT real human voices)\n"
                    "Create placeholders? (y/n): ")
    
    if response.lower() != 'y':
        logger.info("Skipping placeholder creation. Replace with real human samples!")
        return 0
    
    logger.info("\nðŸ“¢ Creating placeholder human samples (for testing only)...")
    logger.warning("âš  WARNING: These are AI-generated with variation - NOT real human voices!")
    logger.info("   For production accuracy, replace with real human recordings.\n")
    
    human_dir = output_dir / "human"
    human_dir.mkdir(parents=True, exist_ok=True)
    
    # Create varied "human" samples using gTTS with different parameters
    placeholder_texts = {
        "en": [
            "I am speaking at a normal pace with natural variation.",
            "This is another sample with different intonation.",
            "Here is a third recording for testing purposes.",
        ],
        "ta": [
            "à®‡à®¤à¯ à®‡à®¯à®²à¯à®ªà®¾à®© à®µà¯‡à®•à®¤à¯à®¤à®¿à®²à¯ à®ªà¯‡à®šà¯à®®à¯ à®®à®¾à®¤à®¿à®°à®¿.",
            "à®‡à®¤à¯ à®®à®±à¯à®±à¯Šà®°à¯ à®ªà®¤à®¿à®µà¯ à®µà®¿à®¤à¯à®¤à®¿à®¯à®¾à®šà®®à®¾à®© à®’à®²à®¿à®¯à¯à®Ÿà®©à¯.",
        ],
        "hi": [
            "à¤¯à¤¹ à¤¸à¤¾à¤®à¤¾à¤¨à¥à¤¯ à¤—à¤¤à¤¿ à¤¸à¥‡ à¤¬à¥‹à¤²à¤¨à¥‡ à¤•à¤¾ à¤¨à¤®à¥‚à¤¨à¤¾ à¤¹à¥ˆà¥¤",
            "à¤¯à¤¹ à¤à¤• à¤”à¤° à¤°à¤¿à¤•à¥‰à¤°à¥à¤¡à¤¿à¤‚à¤— à¤…à¤²à¤— à¤¸à¥à¤µà¤° à¤•à¥‡ à¤¸à¤¾à¤¥ à¤¹à¥ˆà¥¤",
        ],
        "ml": ["à´‡à´¤àµ à´¸à´¾à´§à´¾à´°à´£ à´µàµ‡à´—à´¤à´¯à´¿àµ½ à´¸à´‚à´¸à´¾à´°à´¿à´•àµà´•àµà´¨àµà´¨ à´¸à´¾à´®àµà´ªà´¿àµ¾ à´†à´£àµ."],
        "te": ["à°‡à°¦à°¿ à°¸à°¾à°§à°¾à°°à°£ à°µà±‡à°—à°‚à°¤à±‹ à°®à°¾à°Ÿà±à°²à°¾à°¡à±‡ à°¨à°®à±‚à°¨à°¾."],
    }
    
    count = 0
    for lang_code, texts in placeholder_texts.items():
        for i, text in enumerate(texts, 1):
            try:
                output_file = human_dir / f"human_{lang_code}_{i}.mp3"
                # Use slow=False for slight variation from AI samples
                tts = gTTS(text=text, lang=lang_code, slow=False)
                tts.save(str(output_file))
                logger.info(f"  âœ“ Created placeholder: {output_file.name}")
                count += 1
            except Exception as e:
                logger.error(f"  âœ— Failed: {e}")
    
    logger.info(f"\nâœ“ Created {count} placeholder human samples")
    logger.warning("âš  Remember: Replace these with real human recordings for production!\n")
    
    return count


def main():
    """Main data collection workflow"""
    print("=" * 60)
    print("ENHANCED AI VOICE DETECTION - DATA COLLECTION")
    print("=" * 60)
    
    # Setup directories
    base_dir = Path(__file__).parent.parent
    data_dir = base_dir / "data" / "raw"
    data_dir.mkdir(parents=True, exist_ok=True)
    
    # Generate AI samples with gTTS
    ai_count = generate_gtts_samples(data_dir, SAMPLE_TEXTS)
    logger.info(f"\nâœ“ Generated {ai_count} gTTS AI samples")
    
    # Try to generate with Coqui TTS for diversity
    coqui_count = generate_coqui_tts_samples(data_dir, SAMPLE_TEXTS)
    
    # Create human sample instructions
    create_human_sample_instructions(data_dir)
    
    # Optionally create placeholders
    human_count = create_placeholder_samples(data_dir)
    
    # Summary
    print("\n" + "=" * 60)
    print("DATA COLLECTION SUMMARY")
    print("=" * 60)
    print(f"AI samples (gTTS): {ai_count} files in data/raw/ai")
    if coqui_count > 0:
        print(f"AI samples (Coqui): {coqui_count} files in data/raw/ai_coqui")
    print(f"Human samples: {human_count} files in data/raw/human")
    print(f"\nNext steps:")
    print(f"1. Add more human voice recordings to data/raw/human/")
    if coqui_count == 0:
        print(f"2. (Optional) Install Coqui TTS: pip install TTS")
        print(f"3. Run: python scripts/train_model_enhanced.py")
    else:
        print(f"2. Run: python scripts/train_model_enhanced.py")
    print("=" * 60)


if __name__ == "__main__":
    main()
